{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4cbcf5f",
        "outputId": "d66e1406-b189-4964-ceba-e05f2a32f8e3"
      },
      "source": [
        "!pip install -U langgraph langchain langchain-core groq pydantic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.5)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.5)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4f46a82"
      },
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from typing import TypedDict, Literal, Annotated\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from groq import Groq\n",
        "import operator\n",
        "from pydantic import BaseModel, Field\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "assert api_key is not None, \"GROQ_API_KEY not found in Colab Secrets\"\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = api_key\n",
        "client = Groq()"
      ],
      "metadata": {
        "id": "YFseI1O_46qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Key loaded:\", userdata.get(\"GROQ_API_KEY\") is not None)"
      ],
      "metadata": {
        "id": "RmMFBPm848ck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5e1968-841a-4783-b0d7-2dfaa4af8bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key loaded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def groq_invoke(messages):\n",
        "    groq_messages = []\n",
        "    for m in messages:\n",
        "        if isinstance(m, SystemMessage):\n",
        "            role = \"system\"\n",
        "        elif isinstance(m, HumanMessage):\n",
        "            role = \"user\"\n",
        "        else:\n",
        "            role = \"assistant\"\n",
        "\n",
        "        groq_messages.append({\n",
        "            \"role\": role,\n",
        "            \"content\": m.content\n",
        "        })\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=groq_messages\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "tgzexLEg5jPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BlogEvaluation(BaseModel):\n",
        "    evaluation: Literal[\"approved\", \"needs_improvement\"] = Field(\n",
        "        ..., description=\"Final evaluation result\"\n",
        "    )\n",
        "    feedback: str = Field(..., description=\"Reviewer feedback\")"
      ],
      "metadata": {
        "id": "oII9cn1u5CEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BlogState(TypedDict):\n",
        "    topic: str\n",
        "    blog: str\n",
        "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
        "    feedback: str\n",
        "    iteration: int\n",
        "    max_iteration: int\n",
        "\n",
        "    blog_history: Annotated[list[str], operator.add]\n",
        "    feedback_history: Annotated[list[str], operator.add]"
      ],
      "metadata": {
        "id": "wHOHKlsb56EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_blog(state: BlogState):\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are a professional technical blog writer.\"),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "Write a detailed, structured blog on the following topic:\n",
        "\n",
        "Topic: \"{state['topic']}\"\n",
        "\n",
        "Requirements:\n",
        "- Clear headings and subheadings\n",
        "- Educational, professional tone\n",
        "- No filler content\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    blog = groq_invoke(messages)\n",
        "\n",
        "    return {\n",
        "        \"blog\": blog,\n",
        "        \"blog_history\": [blog]\n",
        "    }"
      ],
      "metadata": {
        "id": "Ajdx-48w6Vo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_blog(state: BlogState):\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You are a strict reviewer evaluating clarity, coherence, and completeness.\"),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "Evaluate the following blog:\n",
        "\n",
        "{state['blog']}\n",
        "\n",
        "Criteria:\n",
        "1. Logical flow\n",
        "2. Technical accuracy\n",
        "3. Readability\n",
        "4. Completeness\n",
        "\n",
        "Respond clearly with:\n",
        "- approved OR needs_improvement\n",
        "- one paragraph feedback\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    raw_feedback = groq_invoke(messages)\n",
        "\n",
        "    evaluation = \"approved\" if \"approved\" in raw_feedback.lower() else \"needs_improvement\"\n",
        "\n",
        "    return {\n",
        "        \"evaluation\": evaluation,\n",
        "        \"feedback\": raw_feedback,\n",
        "        \"feedback_history\": [raw_feedback]\n",
        "    }"
      ],
      "metadata": {
        "id": "j3oA-Vti6Yjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refine_blog(state: BlogState):\n",
        "    messages = [\n",
        "        SystemMessage(content=\"You improve blogs based on reviewer feedback.\"),\n",
        "        HumanMessage(content=f\"\"\"\n",
        "Improve the blog using the feedback below.\n",
        "\n",
        "Feedback:\n",
        "{state['feedback']}\n",
        "\n",
        "Original Blog:\n",
        "{state['blog']}\n",
        "\"\"\")\n",
        "    ]\n",
        "\n",
        "    improved_blog = groq_invoke(messages)\n",
        "\n",
        "    return {\n",
        "        \"blog\": improved_blog,\n",
        "        \"iteration\": state[\"iteration\"] + 1,\n",
        "        \"blog_history\": [improved_blog]\n",
        "    }"
      ],
      "metadata": {
        "id": "l9V_SnYm6b46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_blog(state: BlogState):\n",
        "    if state[\"evaluation\"] == \"approved\" or state[\"iteration\"] >= state[\"max_iteration\"]:\n",
        "        return \"approved\"\n",
        "    else:\n",
        "        return \"needs_improvement\""
      ],
      "metadata": {
        "id": "U1ijRkm56eO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(BlogState)\n",
        "\n",
        "graph.add_node(\"generate\", generate_blog)\n",
        "graph.add_node(\"evaluate\", evaluate_blog)\n",
        "graph.add_node(\"refine\", refine_blog)\n",
        "\n",
        "graph.add_edge(START, \"generate\")\n",
        "graph.add_edge(\"generate\", \"evaluate\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"evaluate\",\n",
        "    route_blog,\n",
        "    {\n",
        "        \"approved\": END,\n",
        "        \"needs_improvement\": \"refine\"\n",
        "    }\n",
        ")\n",
        "\n",
        "graph.add_edge(\"refine\", \"evaluate\")\n",
        "\n",
        "workflow = graph.compile()"
      ],
      "metadata": {
        "id": "xvmNVlK16hih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow"
      ],
      "metadata": {
        "id": "IYvRU6cK6kar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "903c19cb-24e8-4560-8ac8-ab75ee1d9cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7dd3e4d35490>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = {\n",
        "    \"topic\": \"Explain CNN feature extraction in deep learning\",\n",
        "    \"iteration\": 1,\n",
        "    \"max_iteration\": 3\n",
        "}\n",
        "\n",
        "result = workflow.invoke(initial_state)"
      ],
      "metadata": {
        "id": "UMX1k7Hn6nQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FINAL BLOG:\\n\")\n",
        "print(result[\"blog\"])\n",
        "\n",
        "print(\"\\nITERATIONS USED:\", result[\"iteration\"])\n",
        "print(\"TOTAL VERSIONS GENERATED:\", len(result[\"blog_history\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3ZM535jyDSu",
        "outputId": "2b4591e7-fb7e-44bf-ef75-9766aa5f97dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL BLOG:\n",
            "\n",
            "**Extracting Features with Convolutional Neural Networks (CNNs): A Comprehensive Guide**\n",
            "\n",
            "**Introduction**\n",
            "\n",
            " Convolutional Neural Networks (CNNs) have revolutionized the field of deep learning, particularly in image and speech processing tasks. One of the key strengths of CNNs is their ability to extract relevant features from data, which can be then used for classification, object detection, and other tasks. In this blog post, we will delve into the concept of CNN feature extraction, exploring its principles, mechanisms, and applications.\n",
            "\n",
            "**What are Features in Deep Learning?**\n",
            "\n",
            "Before diving into CNNs, let's first understand what features are in the context of deep learning. Features refer to the high-level representations of data that capture essential information, such as patterns, shapes, and textures. In image processing, features might include edges, corners, and objects, while in speech processing, features might include mel-frequency cepstral coefficients (MFCCs).\n",
            "\n",
            "**Convolutional Neural Networks (CNNs)**\n",
            "\n",
            "CNNs are a type of neural network specifically designed for image and speech processing tasks. They consist of multiple layers, each with a specific function:\n",
            "\n",
            "1. **Convolutional Layers**: These layers apply filters to the input data, scanning it in both space (for images) and time (for audio). The filters detect local patterns and are sliding window-like in their operation.\n",
            "2. **Activation Functions**: Used to introduce non-linearity into the network, allowing it to learn complex features.\n",
            "3. **Pooling Layers**: These layers reduce the spatial dimensions of the data, preserving the essential features.\n",
            "4. **Fully Connected Layers**: These layers are used for classification and other tasks.\n",
            "\n",
            "**Feature Extraction in CNNs**\n",
            "\n",
            "Now that we have introduced CNNs, let's look at how feature extraction works in these networks. The process involves multiple stages:\n",
            "\n",
            "1. **Initial Filters**: The first set of filters detect simple patterns, such as edges and corners.\n",
            "2. **Hierarchical Features**: As the network progresses, more complex filters are introduced, capturing larger patterns and shapes.\n",
            "3. **Feature Maps**: The output of each convolutional layer is a feature map, which represents the output of the convolution operation.\n",
            "4. **Pooling Layers**: The feature maps are downscaled using pooling layers, further extracting features.\n",
            "5. **Fully Connected Layers**: The extracted features are then used as input to fully connected layers for classification or other tasks.\n",
            "\n",
            "**Key Mechanisms behind CNN Feature Extraction**\n",
            "\n",
            "Several key mechanisms enable CNNs to extract relevant features from data:\n",
            "\n",
            "1. **Shared Weights**: Shared weights across filters allow CNNs to generalize features across the entire image or audio signal.\n",
            "2. **Translation Invariance**: CNNs are translation-invariant, meaning they are not sensitive to the position of the features in the image or audio signal.\n",
            "3. **Local Connectivity**: The local connection between neurons enables CNNs to capture spatial relationships between features.\n",
            "\n",
            "**Applications of CNN Feature Extraction**\n",
            "\n",
            "CNN feature extraction has been applied to a wide range of tasks, including:\n",
            "\n",
            "1. **Image Classification**: CNNs have achieved state-of-the-art performance on image classification tasks, such as CIFAR-10 and ImageNet.\n",
            "2. **Object Detection**: CNNs have enabled robust object detection in images, including tasks like pedestrian detection and face recognition.\n",
            "3. **Speech Recognition**: CNNs have improved speech recognition systems by extracting features that are more accurate and robust.\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "In conclusion, CNN feature extraction is a powerful tool for extracting relevant features from data. By understanding the principles and mechanisms behind CNNs, we can leverage their strengths in various applications. Whether it's image classification, object detection, or speech recognition, CNN feature extraction has been instrumental in pushing the boundaries of deep learning research.\n",
            "\n",
            "**Further Reading**\n",
            "\n",
            "For a deeper dive into CNNs and their applications, we recommend the following resources:\n",
            "\n",
            "* \"ImageNet Large Scale Visual Recognition Challenge\" (ILSVRC) dataset\n",
            "* \"Convolutional Neural Networks for Image Classification\" (LeCun et al., 1998)\n",
            "* \"Deep Residual Learning for Image Recognition\" (He et al., 2016)\n",
            "\n",
            "We hope this comprehensive guide has provided valuable insights into CNN feature extraction. In our next blog post, we will explore other aspects of deep learning and neural networks. Stay tuned!\n",
            "\n",
            "ITERATIONS USED: 1\n",
            "TOTAL VERSIONS GENERATED: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, blog in enumerate(result[\"blog_history\"], 1):\n",
        "    print(f\"\\n--- BLOG VERSION {i} ---\\n\")\n",
        "    print(blog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nclyC-ov7ud9",
        "outputId": "f5798ddd-4131-46d5-f199-91744800df2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- BLOG VERSION 1 ---\n",
            "\n",
            "**Extracting Features with Convolutional Neural Networks (CNNs): A Comprehensive Guide**\n",
            "\n",
            "**Introduction**\n",
            "\n",
            " Convolutional Neural Networks (CNNs) have revolutionized the field of deep learning, particularly in image and speech processing tasks. One of the key strengths of CNNs is their ability to extract relevant features from data, which can be then used for classification, object detection, and other tasks. In this blog post, we will delve into the concept of CNN feature extraction, exploring its principles, mechanisms, and applications.\n",
            "\n",
            "**What are Features in Deep Learning?**\n",
            "\n",
            "Before diving into CNNs, let's first understand what features are in the context of deep learning. Features refer to the high-level representations of data that capture essential information, such as patterns, shapes, and textures. In image processing, features might include edges, corners, and objects, while in speech processing, features might include mel-frequency cepstral coefficients (MFCCs).\n",
            "\n",
            "**Convolutional Neural Networks (CNNs)**\n",
            "\n",
            "CNNs are a type of neural network specifically designed for image and speech processing tasks. They consist of multiple layers, each with a specific function:\n",
            "\n",
            "1. **Convolutional Layers**: These layers apply filters to the input data, scanning it in both space (for images) and time (for audio). The filters detect local patterns and are sliding window-like in their operation.\n",
            "2. **Activation Functions**: Used to introduce non-linearity into the network, allowing it to learn complex features.\n",
            "3. **Pooling Layers**: These layers reduce the spatial dimensions of the data, preserving the essential features.\n",
            "4. **Fully Connected Layers**: These layers are used for classification and other tasks.\n",
            "\n",
            "**Feature Extraction in CNNs**\n",
            "\n",
            "Now that we have introduced CNNs, let's look at how feature extraction works in these networks. The process involves multiple stages:\n",
            "\n",
            "1. **Initial Filters**: The first set of filters detect simple patterns, such as edges and corners.\n",
            "2. **Hierarchical Features**: As the network progresses, more complex filters are introduced, capturing larger patterns and shapes.\n",
            "3. **Feature Maps**: The output of each convolutional layer is a feature map, which represents the output of the convolution operation.\n",
            "4. **Pooling Layers**: The feature maps are downscaled using pooling layers, further extracting features.\n",
            "5. **Fully Connected Layers**: The extracted features are then used as input to fully connected layers for classification or other tasks.\n",
            "\n",
            "**Key Mechanisms behind CNN Feature Extraction**\n",
            "\n",
            "Several key mechanisms enable CNNs to extract relevant features from data:\n",
            "\n",
            "1. **Shared Weights**: Shared weights across filters allow CNNs to generalize features across the entire image or audio signal.\n",
            "2. **Translation Invariance**: CNNs are translation-invariant, meaning they are not sensitive to the position of the features in the image or audio signal.\n",
            "3. **Local Connectivity**: The local connection between neurons enables CNNs to capture spatial relationships between features.\n",
            "\n",
            "**Applications of CNN Feature Extraction**\n",
            "\n",
            "CNN feature extraction has been applied to a wide range of tasks, including:\n",
            "\n",
            "1. **Image Classification**: CNNs have achieved state-of-the-art performance on image classification tasks, such as CIFAR-10 and ImageNet.\n",
            "2. **Object Detection**: CNNs have enabled robust object detection in images, including tasks like pedestrian detection and face recognition.\n",
            "3. **Speech Recognition**: CNNs have improved speech recognition systems by extracting features that are more accurate and robust.\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "In conclusion, CNN feature extraction is a powerful tool for extracting relevant features from data. By understanding the principles and mechanisms behind CNNs, we can leverage their strengths in various applications. Whether it's image classification, object detection, or speech recognition, CNN feature extraction has been instrumental in pushing the boundaries of deep learning research.\n",
            "\n",
            "**Further Reading**\n",
            "\n",
            "For a deeper dive into CNNs and their applications, we recommend the following resources:\n",
            "\n",
            "* \"ImageNet Large Scale Visual Recognition Challenge\" (ILSVRC) dataset\n",
            "* \"Convolutional Neural Networks for Image Classification\" (LeCun et al., 1998)\n",
            "* \"Deep Residual Learning for Image Recognition\" (He et al., 2016)\n",
            "\n",
            "We hope this comprehensive guide has provided valuable insights into CNN feature extraction. In our next blog post, we will explore other aspects of deep learning and neural networks. Stay tuned!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3PIWjkJ74L3",
        "outputId": "96d397fe-dad8-4ccf-a508-b097e26f0878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['topic', 'blog', 'evaluation', 'feedback', 'iteration', 'max_iteration', 'blog_history', 'feedback_history'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "evaluation_topics = [\n",
        "    \"Explain CNN feature extraction in deep learning\",\n",
        "    \"What is Retrieval Augmented Generation\",\n",
        "    \"Applications of transformers in NLP\",\n",
        "    \"Explain explainable AI methods\",\n",
        "    \"Computer vision applications in agriculture\"\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for topic in evaluation_topics:\n",
        "    start_time = time.time()\n",
        "\n",
        "    result = workflow.invoke({\n",
        "        \"topic\": topic,\n",
        "        \"iteration\": 1,\n",
        "        \"max_iteration\": 3\n",
        "    })\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    results.append({\n",
        "        \"Topic\": topic,\n",
        "        \"Latency_seconds\": round(end_time - start_time, 2),\n",
        "        \"Iterations_used\": result[\"iteration\"],\n",
        "        \"Approved\": result[\"evaluation\"] == \"approved\"\n",
        "    })\n",
        "\n",
        "performance_df = pd.DataFrame(results)\n",
        "performance_df\n"
      ],
      "metadata": {
        "id": "dG5Eu6Bw8caS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "68adf560-2f10-4934-e35d-2be670a93da7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Topic  Latency_seconds  \\\n",
              "0  Explain CNN feature extraction in deep learning             2.54   \n",
              "1           What is Retrieval Augmented Generation             2.68   \n",
              "2              Applications of transformers in NLP             2.19   \n",
              "3                   Explain explainable AI methods            11.50   \n",
              "4      Computer vision applications in agriculture            41.54   \n",
              "\n",
              "   Iterations_used  Approved  \n",
              "0                1      True  \n",
              "1                1      True  \n",
              "2                1      True  \n",
              "3                1      True  \n",
              "4                2      True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5f2fb59-9930-4c11-8a90-1223cd520f75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Latency_seconds</th>\n",
              "      <th>Iterations_used</th>\n",
              "      <th>Approved</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explain CNN feature extraction in deep learning</td>\n",
              "      <td>2.54</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is Retrieval Augmented Generation</td>\n",
              "      <td>2.68</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Applications of transformers in NLP</td>\n",
              "      <td>2.19</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Explain explainable AI methods</td>\n",
              "      <td>11.50</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Computer vision applications in agriculture</td>\n",
              "      <td>41.54</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5f2fb59-9930-4c11-8a90-1223cd520f75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5f2fb59-9930-4c11-8a90-1223cd520f75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5f2fb59-9930-4c11-8a90-1223cd520f75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6810e8b-f206-42cb-a27c-3754f6a7a6da\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6810e8b-f206-42cb-a27c-3754f6a7a6da')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6810e8b-f206-42cb-a27c-3754f6a7a6da button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ba3e123b-8f26-4ae1-9cf6-f01efc04a9e2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('performance_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba3e123b-8f26-4ae1-9cf6-f01efc04a9e2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('performance_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "performance_df",
              "summary": "{\n  \"name\": \"performance_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Topic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is Retrieval Augmented Generation\",\n          \"Computer vision applications in agriculture\",\n          \"Applications of transformers in NLP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Latency_seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.92196206117955,\n        \"min\": 2.19,\n        \"max\": 41.54,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.68,\n          41.54,\n          2.19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Iterations_used\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Approved\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Latency (seconds):\", round(performance_df[\"Latency_seconds\"].mean(), 2))\n",
        "print(\"Average Iterations Used:\", round(performance_df[\"Iterations_used\"].mean(), 2))\n",
        "print(\"Approval Rate (%):\", round(performance_df[\"Approved\"].mean() * 100, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaUF6ZMD8-gD",
        "outputId": "03c2db00-3c76-4746-a398-6786cfd618f6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Latency (seconds): 12.09\n",
            "Average Iterations Used: 1.2\n",
            "Approval Rate (%): 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Evaluation (Human-in-the-loop)\n",
        "\n",
        "Each final blog was manually evaluated on a 15 scale.\n",
        "\n",
        "| Topic | Coherence (15) | Relevance (15) |\n",
        "|------|----------------|----------------|\n",
        "| CNN feature extraction | 5 | 5 |\n",
        "| RAG systems | 4 | 5 |\n",
        "| Transformers in NLP | 5 | 4 |\n",
        "| Explainable AI | 4 | 4 |\n",
        "| CV in agriculture | 5 | 5 |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oGN3uavN_E7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Human Evaluation Protocol\n",
        "\n",
        "The generated blogs were evaluated manually by the project author using a fixed rubric:\n",
        "\n",
        "**Coherence (15):**\n",
        "\n",
        "1  Disorganized, unclear  \n",
        "3  Mostly clear with minor issues  \n",
        "5  Highly structured and professional  \n",
        "\n",
        "**Relevance (15):**\n",
        "\n",
        "1  Partially or off-topic  \n",
        "3  Mostly relevant  \n",
        "5  Fully addresses the topic  \n",
        "\n",
        "This evaluation reflects human judgement and is used for qualitative system assessment."
      ],
      "metadata": {
        "id": "P_p1fezV_ePr"
      }
    }
  ]
}